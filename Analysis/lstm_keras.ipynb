{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dbpedia_14 (/home/sriteja/.cache/huggingface/datasets/dbpedia_14/dbpedia_14/2.0.0/01dab9e10d969eadcdbc918be5a09c9190a24caeae33b10eee8f367a1e3f1f0c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e467e3dd9bc64b259cac5a4c86f39faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dbpedia_14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'title', 'content'],\n",
      "        num_rows: 560000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'title', 'content'],\n",
      "        num_rows: 70000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Convert train and test datasets to arrays\n",
    "train_data_title = train_dataset['title']\n",
    "train_data_content = train_dataset['content']\n",
    "train_labels = train_dataset['label']\n",
    "test_data_title = test_dataset['title']\n",
    "test_data_content = test_dataset['content']\n",
    "test_labels = test_dataset['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from pkl file\n",
    "with open('dbpedia_train_tokens.pkl', 'rb') as file:\n",
    "    tokens = pickle.load(file)\n",
    "    \n",
    "with open('dbpedia_test_tokens.pkl', 'rb') as file:\n",
    "    tokens_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in train data replace every 1000th word with UNK randomly\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    for j in range(len(tokens[i])):\n",
    "        if random.randint(1, 1000) == 1:\n",
    "            tokens[i][j] = 'UNK'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  1473\n",
      "Min length:  3\n",
      "Number of sentences with length > 100:  1207\n",
      "558793\n",
      "558793\n",
      "69839\n",
      "69839\n"
     ]
    }
   ],
   "source": [
    "# find length of longest sentence\n",
    "max_len = 0\n",
    "for i in range(len(tokens)):\n",
    "    if len(tokens[i]) > max_len:\n",
    "        max_len = len(tokens[i])\n",
    "        \n",
    "# find length of shortest sentence\n",
    "min_len = 1000000\n",
    "for i in range(len(tokens)):\n",
    "    if len(tokens[i]) < min_len:\n",
    "        min_len = len(tokens[i])\n",
    "        \n",
    "print(\"Max length: \", max_len)\n",
    "print(\"Min length: \", min_len)\n",
    "\n",
    "# number of sentences with length > 100\n",
    "count = 0\n",
    "for i in range(len(tokens)):\n",
    "    if len(tokens[i]) > 100:\n",
    "        count += 1\n",
    "        \n",
    "print(\"Number of sentences with length > 100: \", count)\n",
    "\n",
    "# remove sentences with length > 100 along with their labels\n",
    "new_tokens = []\n",
    "new_labels = []\n",
    "for i in range(len(tokens)):\n",
    "    if len(tokens[i]) <= 100:\n",
    "        new_tokens.append(tokens[i])\n",
    "        new_labels.append(train_labels[i])\n",
    "        \n",
    "# remove so in test also\n",
    "new_tokens_test = []\n",
    "new_labels_test = []\n",
    "for i in range(len(tokens_test)):\n",
    "    if len(tokens_test[i]) <= 100:\n",
    "        new_tokens_test.append(tokens_test[i])\n",
    "        new_labels_test.append(test_labels[i])\n",
    "        \n",
    "print(len(new_tokens))\n",
    "print(len(new_labels))\n",
    "print(len(new_tokens_test))\n",
    "print(len(new_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  507\n",
      "Min length:  4\n"
     ]
    }
   ],
   "source": [
    "# for tetst data\n",
    "# find length of longest sentence\n",
    "max_len_test = 0\n",
    "for i in range(len(tokens_test)):\n",
    "    if len(tokens_test[i]) > max_len_test:\n",
    "        max_len_test = len(tokens_test[i])\n",
    "        \n",
    "# find length of shortest sentence\n",
    "min_len_test = 1000000\n",
    "for i in range(len(tokens_test)):\n",
    "    if len(tokens_test[i]) < min_len_test:\n",
    "        min_len_test = len(tokens_test[i])\n",
    "        \n",
    "print(\"Max length: \", max_len_test)\n",
    "print(\"Min length: \", min_len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding to all sentences and S and EOS tokens\n",
    "def padding(tokens, max_len):\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = ['S'] + tokens[i] + ['EOS']\n",
    "        while len(tokens[i]) < max_len:\n",
    "            tokens[i].append('PAD')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 102\n",
    "tokens = padding(new_tokens, max_len)\n",
    "tokens_test = padding(new_tokens_test, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523562\n",
      "lenticular\n",
      "694806\n",
      "36282\n",
      "442904\n",
      "454389\n",
      "341337\n",
      "439052\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a vocabulary by collecting unique words from the training data\n",
    "vocab = set()\n",
    "for token in tokens:\n",
    "    vocab.update(token)\n",
    "\n",
    "# Create a dictionary to map words to indices in the vocabulary\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "print(word_to_idx['the'])\n",
    "print(idx_to_word[0])\n",
    "print(word_to_idx['NUM'])\n",
    "print(word_to_idx['UNK'])\n",
    "print(word_to_idx['PAD'])\n",
    "print(word_to_idx['S'])\n",
    "print(word_to_idx['EOS'])\n",
    "print(word_to_idx['MID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 14\n",
    "vocab_size = len(vocab)\n",
    "num_epochs = 3\n",
    "learning_rate = 0.00001\n",
    "embedding_size = 300\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 04:48:53.503300: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-01 04:48:53.529506: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 04:48:53.648352: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 04:48:53.649080: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 04:48:54.452064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-01 04:49:10.680790: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTMCell, RNN, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert tokens and labels to Keras format\n",
    "# Note: Ensure tokens and new_labels are numpy arrays\n",
    "X_train = [[word_to_idx.get(token, word_to_idx['UNK']) for token in sentence] for sentence in tokens]\n",
    "X_test = [[word_to_idx.get(token, word_to_idx['UNK']) for token in sentence] for sentence in tokens_test]\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Convert labels to one-hot format\n",
    "y_train = to_categorical(new_labels, num_classes=num_classes)\n",
    "y_test = to_categorical(new_labels_test, num_classes=num_classes)\n",
    "\n",
    "# GPU Configuration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, mask_zero=True))\n",
    "# model.add(RNN(LSTMCell(hidden_size)))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 12:36:35.657519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [32,14]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/17462 [..............................] - ETA: 20:50:08 - loss: 2.6268 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 12:36:40.061046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [32,14]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2/17462 [..............................] - ETA: 18:20:26 - loss: 2.6260 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 12:36:43.994149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [32,14]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.utils import Progbar\n",
    "\n",
    "# # Train model\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    \n",
    "#     # Initialize Progbar with the total number of batches\n",
    "#     progbar = Progbar(len(X_train) // batch_size)\n",
    "    \n",
    "#     # Training\n",
    "#     for i in range(0, len(X_train), batch_size):\n",
    "#         X_batch = X_train[i:i + batch_size]\n",
    "#         y_batch = y_train[i:i + batch_size]\n",
    "        \n",
    "#         # Check batch size; skip if it's not 32\n",
    "#         if len(X_batch) != 32:\n",
    "#             continue\n",
    "        \n",
    "#         batch_loss, batch_acc = model.train_on_batch(X_batch, y_batch)\n",
    "        \n",
    "#         # Update progbar with the batch's metrics\n",
    "#         progbar.add(1, values=[('loss', batch_loss), ('accuracy', batch_acc)])\n",
    "    \n",
    "#     # Save the model after each epoch\n",
    "#     model.save(f\"dbpedia_keras_model_epoch_{epoch+1}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model lstm_dbpedia.keras\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('lstm_dbpedia.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a new model that outputs both the predictions and the embeddings\n",
    "# Assume 'embedding' is the name of your embedding layer\n",
    "embedding_output = model.get_layer('embedding').output\n",
    "grad_model = tf.keras.models.Model(inputs=model.input, outputs=[model.output, embedding_output])\n",
    "\n",
    "# Select a sample\n",
    "sample = X_test[0:1]\n",
    "\n",
    "# Compute the gradients\n",
    "with tf.GradientTape() as tape:\n",
    "    # Run this sample through the grad_model\n",
    "    predictions, embeddings = grad_model(sample)\n",
    "    # Choose the class with the highest probability\n",
    "    class_idx = np.argmax(predictions[0])\n",
    "    # Compute the loss\n",
    "    loss = predictions[:, class_idx]\n",
    "\n",
    "    # Ensure the embeddings are being watched\n",
    "    tape.watch(embeddings)\n",
    "\n",
    "# Get the gradients of the loss with respect to the embedding output\n",
    "gradients = tape.gradient(loss, embeddings)\n",
    "\n",
    "# Check if gradients are None\n",
    "if gradients is not None:\n",
    "    # Sum the gradients across the input sequence\n",
    "    summed_gradients = tf.reduce_sum(tf.abs(gradients), axis=-1).numpy()[0]\n",
    "\n",
    "    # Plot\n",
    "    plt.bar(range(len(summed_gradients)), summed_gradients)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Gradients could not be computed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
