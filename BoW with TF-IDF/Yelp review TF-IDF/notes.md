# Notes BoW with TF-IDF dbpedia

## Logisitic Regression

```txt
Accuracy: 0.529
              precision    recall  f1-score   support

           0       0.64      0.68      0.66       993
           1       0.46      0.48      0.47      1030
           2       0.40      0.40      0.40       964
           3       0.48      0.47      0.47      1004
           4       0.67      0.61      0.64      1009

    accuracy                           0.53      5000
   macro avg       0.53      0.53      0.53      5000
weighted avg       0.53      0.53      0.53      5000
```

## Linear Layer

```txt
Accuracy of the network on the 50000 test inputs: 55.654 %
Confusion Matrix:
[[7396 1948  237   73  346]
 [2648 4757 1827  294  474]
 [ 838 2153 4189 1768 1052]
 [ 321  473 1719 3886 3601]
 [ 324  132  304 1641 7599]]
Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.74      0.69     10000
           1       0.50      0.48      0.49     10000
           2       0.51      0.42      0.46     10000
           3       0.51      0.39      0.44     10000
           4       0.58      0.76      0.66     10000

    accuracy                           0.56     50000
   macro avg       0.55      0.56      0.55     50000
weighted avg       0.55      0.56      0.55     50000
```
