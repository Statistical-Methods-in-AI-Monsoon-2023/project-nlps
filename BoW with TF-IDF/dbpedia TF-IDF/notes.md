# Notes BoW with TF-IDF dbpedia

## Logisitic Regression

```txt
Accuracy: 0.963
              precision    recall  f1-score   support

           0       0.95      0.91      0.93       399
           1       0.95      0.98      0.97       341
           2       0.91      0.90      0.91       354
           3       0.98      0.98      0.98       371
           4       0.98      0.96      0.97       339
           5       0.96      0.99      0.97       343
           6       0.95      0.96      0.95       383
           7       0.98      0.98      0.98       326
           8       1.00      0.99      0.99       364
           9       0.96      0.97      0.96       323
          10       0.96      0.97      0.96       365
          11       0.98      0.98      0.98       364
          12       0.99      0.97      0.98       383
          13       0.93      0.96      0.95       345

    accuracy                           0.96      5000
   macro avg       0.96      0.96      0.96      5000
weighted avg       0.96      0.96      0.96      5000
```

## Linear Layer

```txt
Accuracy of the network on the 70000 test inputs: 96.12571428571428 %
Confusion Matrix:
[[4555   50   46   11   24   62   65   10    1    0    5   55   29   87]
 [  40 4877   13    1   17    6   31    4    2    0    1    0    4    4]
 [  36    8 4570   12   83    1   11    0    1    0    1  104   33  140]
 [   3    1   51 4909   20    2    4    0    0    2    1    1    5    1]
 [  15   15   84   15 4842    4    7    0    1    1    0    0    5   11]
 [  45    4    2    2    2 4912   10    5    0    3    2    3    7    3]
 [  56   65   11    4   16   16 4783   31    4    1    0    3    3    7]
 [   4    2    2    1    4    3   31 4935    9    3    3    0    1    2]
 [   4    9    4    1    7    0   30   58 4880    3    0    0    2    2]
 [   2    5    9    3    5    1    1   14    2 4809  141    0    3    5]
 [  13    2    4    0    1    2    2   12    0   87 4869    1    2    5]
 [  13    3   60    4    4    2    6    3    0    2    0 4868   21   14]
 [  10    4   27    9    5   10    9    6    0    0    1   35 4812   72]
 [  63   26   66   17   25    6   15    1    2    4    2   17   89 4667]]
Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.91      0.92      5000
           1       0.96      0.98      0.97      5000
           2       0.92      0.91      0.92      5000
           3       0.98      0.98      0.98      5000
           4       0.96      0.97      0.96      5000
           5       0.98      0.98      0.98      5000
           6       0.96      0.96      0.96      5000
           7       0.97      0.99      0.98      5000
           8       1.00      0.98      0.99      5000
           9       0.98      0.96      0.97      5000
          10       0.97      0.97      0.97      5000
          11       0.96      0.97      0.97      5000
          12       0.96      0.96      0.96      5000
          13       0.93      0.93      0.93      5000

    accuracy                           0.96     70000
   macro avg       0.96      0.96      0.96     70000
weighted avg       0.96      0.96      0.96     70000
```
