# Notes BoW dbpedia

## Logisitic Regression

```txt
Accuracy: 0.9582
              precision    recall  f1-score   support

           0       0.93      0.91      0.92       399
           1       0.94      0.98      0.96       341
           2       0.90      0.91      0.90       354
           3       0.98      0.97      0.97       371
           4       0.97      0.96      0.96       339
           5       0.96      0.98      0.97       343
           6       0.97      0.95      0.96       383
           7       0.98      0.98      0.98       326
           8       0.97      1.00      0.98       364
           9       0.93      0.97      0.95       323
          10       0.97      0.95      0.96       365
          11       0.97      0.96      0.97       364
          12       0.99      0.97      0.98       383
          13       0.95      0.95      0.95       345

    accuracy                           0.96      5000
   macro avg       0.96      0.96      0.96      5000
weighted avg       0.96      0.96      0.96      5000
```

## Linear Layer

```txt
Accuracy of the network on the 70000 test inputs: 97.45285714285714 %
Confusion Matrix:
[[4731   42   31    4   16   41   48    7    4    3    7   18    9   39]
 [  44 4899    5    1    6    0   32    4    2    1    2    1    0    3]
 [  31    5 4733    9   71    1    8    1    1    4    0   46   25   65]
 [   3    2   34 4933   12    0    0    1    1    8    0    2    1    3]
 [   9   10   73    9 4868    1    6    1    2    4    0    2    6    9]
 [  49    0    3    0    3 4921   10    4    3    1    1    1    2    2]
 [  73   44    9    0   11   12 4803   35    5    2    0    1    3    2]
 [   5    0    0    0    2    1   26 4953    9    1    0    1    1    1]
 [   2    1    1    2    1    0    9   13 4970    0    0    0    0    1]
 [   1    0    3    0    0    2    1    5    3 4901   82    0    0    2]
 [  13    0    0    0    0    2    1    7    1   91 4882    0    0    3]
 [   6    0   35    2    0    1    1    2    1    0    0 4930   14    8]
 [  10    1   17    4    0    1    2    1    0    2    0   17 4904   41]
 [  50    9   59    5   11    5    8    3    1    5    2   10   43 4789]]
Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.95      0.94      5000
           1       0.98      0.98      0.98      5000
           2       0.95      0.95      0.95      5000
           3       0.99      0.99      0.99      5000
           4       0.97      0.97      0.97      5000
           5       0.99      0.98      0.99      5000
           6       0.97      0.96      0.96      5000
           7       0.98      0.99      0.99      5000
           8       0.99      0.99      0.99      5000
           9       0.98      0.98      0.98      5000
          10       0.98      0.98      0.98      5000
          11       0.98      0.99      0.98      5000
          12       0.98      0.98      0.98      5000
          13       0.96      0.96      0.96      5000

    accuracy                           0.97     70000
   macro avg       0.97      0.97      0.97     70000
weighted avg       0.97      0.97      0.97     70000
```
