{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tqdm as notebook_tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:12:24.225096Z","iopub.status.busy":"2023-10-31T21:12:24.224826Z","iopub.status.idle":"2023-10-31T21:13:05.523768Z","shell.execute_reply":"2023-10-31T21:13:05.522769Z","shell.execute_reply.started":"2023-10-31T21:12:24.225073Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# import torch\n","# import torch.nn as nn\n","# import torch.optim as optim\n","\n","from datasets import load_dataset\n","\n","dataset = load_dataset(\"yelp_review_full\")\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:13:05.532326Z","iopub.status.busy":"2023-10-31T21:13:05.532027Z","iopub.status.idle":"2023-10-31T21:13:07.895500Z","shell.execute_reply":"2023-10-31T21:13:07.894499Z","shell.execute_reply.started":"2023-10-31T21:13:05.532295Z"},"trusted":true},"outputs":[],"source":["import pickle\n","# with open('yelp_dataset.pkl', 'wb') as file:\n","#     pickle.dump(dataset, file)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# with open('yelp_dataset.pkl', 'rb') as file:\n","#     dataset = pickle.load(file)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'text'],\n","        num_rows: 650000\n","    })\n","    test: Dataset({\n","        features: ['label', 'text'],\n","        num_rows: 50000\n","    })\n","})\n"]}],"source":["print(dataset)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:13:07.898581Z","iopub.status.busy":"2023-10-31T21:13:07.898168Z","iopub.status.idle":"2023-10-31T21:13:10.092434Z","shell.execute_reply":"2023-10-31T21:13:10.091269Z","shell.execute_reply.started":"2023-10-31T21:13:07.898546Z"},"trusted":true},"outputs":[],"source":["train_dataset = dataset['train']\n","test_dataset = dataset['test']\n","\n","# Convert train and test datasets to arrays\n","train_data = train_dataset['text']\n","train_labels = train_dataset['label']\n","test_data = test_dataset['text']\n","test_labels = test_dataset['label']\n","\n","# Convert labels to lists (optional)\n","# train_labels = train_labels.tolist()\n","# test_labels = test_labels.tolist()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\n","4\n"]}],"source":["print(train_data[0])\n","print(train_labels[0])\n"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/revanthgundam/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/revanthgundam/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: contractions in /opt/homebrew/lib/python3.11/site-packages (0.1.73)\n","Requirement already satisfied: textsearch>=0.0.21 in /opt/homebrew/lib/python3.11/site-packages (from contractions) (0.0.24)\n","Requirement already satisfied: anyascii in /opt/homebrew/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n","Requirement already satisfied: pyahocorasick in /opt/homebrew/lib/python3.11/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["import sys  \n","!{sys.executable} -m pip install contractions\n","import contractions"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/revanthgundam/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# import re\n","# import nltk\n","# from nltk.corpus import stopwords\n","# from nltk.tokenize import word_tokenize\n","# # nltk.download('stopwords')\n","# nltk.download('punkt')\n","\n","# # def custom_contractions_fix(text):\n","# #     # Define custom contractions to expand\n","# #     contractions_dict = {\n","# #         \"don't\": \"do not\",\n","# #         \"doesn't\": \"does not\",\n","# #         \"didn't\": \"did not\",\n","# #         # Add more contractions as needed\n","# #     }\n","    \n","# #     # Use a regular expression to find and replace contractions\n","# #     contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n","    \n","# #     def replace(match):\n","# #         return contractions_dict[match.group(0)]\n","    \n","# #     expanded_text = contractions_re.sub(replace, text)\n","# #     return expanded_text\n","\n","\n","# def tokenize_text(text):\n","    \n","#     # if there is a word between () then write it once\n","#     text = re.sub(r'\\((.*?)\\)', r'\\1', text)\n","    \n","#     # Apply custom contractions expansion\n","#     # text = custom_contractions_fix(text)\n","    \n","#     expanded_words = []\n","#     for word in text.split():\n","#         # using contractions.fix to expand the shortened words\n","#         # print(word)\n","#         try:\n","#             expanded_words.append(contractions.fix(word))\n","#         except:\n","#             expanded_words.append(word)\n","#         # expanded_words.append(contractions.fix(word)) \n","        \n","#     expanded_text = ' '.join(expanded_words)\n","#     text = expanded_text  \n","    \n","#     # Replace hyphens with spaces\n","#     text = text.replace('-', ' ')\n","    \n","#     # replace colons with spaces\n","#     text = text.replace(':', ' ')\n","    \n","#     # replace commas with spaces\n","#     text = text.replace(',', ' ')\n","    \n","#     tokens = nltk.word_tokenize(text)\n","        \n","#     # Convert to lowercase\n","#     tokens = [w.lower() for w in tokens]\n","    \n","#     # Remove periods\n","#     tokens = [w.replace('.', '') for w in tokens]\n","    \n","#     # replace all numbers with <num>\n","#     tokens = [re.sub(r'\\d+', 'NUM', w) for w in tokens]\n","    \n","#     # replace the word mid everywhere with MID\n","#     tokens = [w.replace('mid', 'MID') for w in tokens]\n","    \n","    \n","#     # Remove punctuation and numbers\n","#     tokens = [word for word in tokens if word.isalpha()]\n","    \n","#     return tokens\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["650000\n","0\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","41000\n","42000\n","43000\n","44000\n","45000\n","46000\n","47000\n","48000\n","49000\n","50000\n","51000\n","52000\n","53000\n","54000\n","55000\n","56000\n","57000\n","58000\n","59000\n","60000\n","61000\n","62000\n","63000\n","64000\n","65000\n","66000\n","67000\n","68000\n","69000\n","70000\n","71000\n","72000\n","73000\n","74000\n","75000\n","76000\n","77000\n","78000\n","79000\n","80000\n","81000\n","82000\n","83000\n","84000\n","85000\n","86000\n","87000\n","88000\n","89000\n","90000\n","91000\n","92000\n","93000\n","94000\n","95000\n","96000\n","97000\n","98000\n","99000\n","100000\n","101000\n","102000\n","103000\n","104000\n","105000\n","106000\n","107000\n","108000\n","109000\n","110000\n","111000\n","112000\n","113000\n","114000\n","115000\n","116000\n","117000\n","118000\n","119000\n","120000\n","121000\n","122000\n","123000\n","124000\n","125000\n","126000\n","127000\n","128000\n","129000\n","130000\n","131000\n","132000\n","133000\n","134000\n","135000\n","136000\n","137000\n","138000\n","139000\n","140000\n","141000\n","142000\n","143000\n","144000\n","145000\n","146000\n","147000\n","148000\n","149000\n","150000\n","151000\n","152000\n","153000\n","154000\n","155000\n","156000\n","157000\n","158000\n","159000\n","160000\n","161000\n","162000\n","163000\n","164000\n","165000\n","166000\n","167000\n","168000\n","169000\n","170000\n","171000\n","172000\n","173000\n","174000\n","175000\n","176000\n","177000\n","178000\n","179000\n","180000\n","181000\n","182000\n","183000\n","184000\n","185000\n","186000\n","187000\n","188000\n","189000\n","190000\n","191000\n","192000\n","193000\n","194000\n","195000\n","196000\n","197000\n","198000\n","199000\n","200000\n","201000\n","202000\n","203000\n","204000\n","205000\n","206000\n","207000\n","208000\n","209000\n","210000\n","211000\n","212000\n","213000\n","214000\n","215000\n","216000\n","217000\n","218000\n","219000\n","220000\n","221000\n","222000\n","223000\n","224000\n","225000\n","226000\n","227000\n","228000\n","229000\n","230000\n","231000\n","232000\n","233000\n","234000\n","235000\n","236000\n","237000\n","238000\n","239000\n","240000\n","241000\n","242000\n","243000\n","244000\n","245000\n","246000\n","247000\n","248000\n","249000\n","250000\n","251000\n","252000\n","253000\n","254000\n","255000\n","256000\n","257000\n","258000\n","259000\n","260000\n","261000\n","262000\n","263000\n","264000\n","265000\n","266000\n","267000\n","268000\n","269000\n","270000\n","271000\n","272000\n","273000\n","274000\n","275000\n","276000\n","277000\n","278000\n","279000\n","280000\n","281000\n","282000\n","283000\n","284000\n","285000\n","286000\n","287000\n","288000\n","289000\n","290000\n","291000\n","292000\n","293000\n","294000\n","295000\n","296000\n","297000\n","298000\n","299000\n","300000\n","301000\n","302000\n","303000\n","304000\n","305000\n","306000\n","307000\n","308000\n","309000\n","310000\n","311000\n","312000\n","313000\n","314000\n","315000\n","316000\n","317000\n","318000\n","319000\n","320000\n","321000\n","322000\n","323000\n","324000\n","325000\n","326000\n","327000\n","328000\n","329000\n","330000\n","331000\n","332000\n","333000\n","334000\n","335000\n","336000\n","337000\n","338000\n","339000\n","340000\n","341000\n","342000\n","343000\n","344000\n","345000\n","346000\n","347000\n","348000\n","349000\n","350000\n","351000\n","352000\n","353000\n","354000\n","355000\n","356000\n","357000\n","358000\n","359000\n","360000\n","361000\n","362000\n","363000\n","364000\n","365000\n","366000\n","367000\n","368000\n","369000\n","370000\n","371000\n","372000\n","373000\n","374000\n","375000\n","376000\n","377000\n","378000\n","379000\n","380000\n","381000\n","382000\n","383000\n","384000\n","385000\n","386000\n","387000\n","388000\n","389000\n","390000\n","391000\n","392000\n","393000\n","394000\n","395000\n","396000\n","397000\n","398000\n","399000\n","400000\n","401000\n","402000\n","403000\n","404000\n","405000\n","406000\n","407000\n","408000\n","409000\n","410000\n","411000\n","412000\n","413000\n","414000\n","415000\n","416000\n","417000\n","418000\n","419000\n","420000\n","421000\n","422000\n","423000\n","424000\n","425000\n","426000\n","427000\n","428000\n","429000\n","430000\n","431000\n","432000\n","433000\n","434000\n","435000\n","436000\n","437000\n","438000\n","439000\n","440000\n","441000\n","442000\n","443000\n","444000\n","445000\n","446000\n","447000\n","448000\n","449000\n","450000\n","451000\n","452000\n","453000\n","454000\n","455000\n","456000\n","457000\n","458000\n","459000\n","460000\n","461000\n","462000\n","463000\n","464000\n","465000\n","466000\n","467000\n","468000\n","469000\n","470000\n","471000\n","472000\n","473000\n","474000\n","475000\n","476000\n","477000\n","478000\n","479000\n","480000\n","481000\n","482000\n","483000\n","484000\n","485000\n","486000\n","487000\n","488000\n","489000\n","490000\n","491000\n","492000\n","493000\n","494000\n","495000\n","496000\n","497000\n","498000\n","499000\n","500000\n","501000\n","502000\n","503000\n","504000\n","505000\n","506000\n","507000\n","508000\n","509000\n","510000\n","511000\n","512000\n","513000\n","514000\n","515000\n","516000\n","517000\n","518000\n","519000\n","520000\n","521000\n","522000\n","523000\n","524000\n","525000\n","526000\n","527000\n","528000\n","529000\n","530000\n","531000\n","532000\n","533000\n","534000\n","535000\n","536000\n","537000\n","538000\n","539000\n","540000\n","541000\n","542000\n","543000\n","544000\n","545000\n","546000\n","547000\n","548000\n","549000\n","550000\n","551000\n","552000\n","553000\n","554000\n","555000\n","556000\n","557000\n","558000\n","559000\n","560000\n","561000\n","562000\n","563000\n","564000\n","565000\n","566000\n","567000\n","568000\n","569000\n","570000\n","571000\n","572000\n","573000\n","574000\n","575000\n","576000\n","577000\n","578000\n","579000\n","580000\n","581000\n","582000\n","583000\n","584000\n","585000\n","586000\n","587000\n","588000\n","589000\n","590000\n","591000\n","592000\n","593000\n","594000\n","595000\n","596000\n","597000\n","598000\n","599000\n","600000\n","601000\n","602000\n","603000\n","604000\n","605000\n","606000\n","607000\n","608000\n","609000\n","610000\n","611000\n","612000\n","613000\n","614000\n","615000\n","616000\n","617000\n","618000\n","619000\n","620000\n","621000\n","622000\n","623000\n","624000\n","625000\n","626000\n","627000\n","628000\n","629000\n","630000\n","631000\n","632000\n","633000\n","634000\n","635000\n","636000\n","637000\n","638000\n","639000\n","640000\n","641000\n","642000\n","643000\n","644000\n","645000\n","646000\n","647000\n","648000\n","649000\n"]}],"source":["# tokens = []\n","# print(len(train_data))\n","\n","# for i in range(len(train_data)):\n","#     tokens.append(tokenize_text(train_data[i]))\n","#     if i % 1000 == 0:\n","#         print(i)\n","\n","# # save to pkl file\n","# with open('yelp_train_tokens_no_stop.pkl', 'wb') as file:\n","#     pickle.dump(tokens, file)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["50000\n","0\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","41000\n","42000\n","43000\n","44000\n","45000\n","46000\n","47000\n","48000\n","49000\n"]}],"source":["# tokens_test = []\n","# print(len(test_data))\n","\n","# for i in range(len(test_data)):\n","#     tokens_test.append(tokenize_text(test_data[i]))\n","#     if i % 1000 == 0:\n","#         print(i)\n","\n","# with open('yelp_test_tokens_no_stop.pkl', 'wb') as file:\n","#     pickle.dump(tokens_test, file)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["with open('yelp_train_tokens_no_stop.pkl', 'rb') as file:\n","    train_tokens = pickle.load(file)\n","\n","with open('yelp_test_tokens_no_stop.pkl', 'rb') as file:\n","    test_tokens = pickle.load(file)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:28:23.111490Z","iopub.status.busy":"2023-10-31T21:28:23.111100Z","iopub.status.idle":"2023-10-31T21:29:33.994635Z","shell.execute_reply":"2023-10-31T21:29:33.993716Z","shell.execute_reply.started":"2023-10-31T21:28:23.111463Z"},"trusted":true},"outputs":[],"source":["# in train data replace every 1000th word with UNK randomly\n","\n","import random\n","\n","for i in range(len(train_tokens)):\n","    for j in range(len(train_tokens[i])):\n","        if random.randint(1, 1000) == 1:\n","            train_tokens[i][j] = 'UNK'\n","        "]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:29:33.996247Z","iopub.status.busy":"2023-10-31T21:29:33.995916Z","iopub.status.idle":"2023-10-31T21:29:34.002276Z","shell.execute_reply":"2023-10-31T21:29:34.001149Z","shell.execute_reply.started":"2023-10-31T21:29:33.996208Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["650000\n","50000\n"]}],"source":["tokens = train_tokens\n","tokens_test = test_tokens\n","print(len(tokens))\n","print(len(tokens_test))"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:29:34.004274Z","iopub.status.busy":"2023-10-31T21:29:34.003963Z","iopub.status.idle":"2023-10-31T21:29:34.700050Z","shell.execute_reply":"2023-10-31T21:29:34.699004Z","shell.execute_reply.started":"2023-10-31T21:29:34.004240Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Max length:  1049\n","Min length:  0\n","Number of sentences with length > 250:  84907\n"]}],"source":["# find length of longest sentence\n","max_len = 0\n","for i in range(len(tokens)):\n","    if len(tokens[i]) > max_len:\n","        max_len = len(tokens[i])\n","        \n","# find length of shortest sentence\n","min_len = 1000000\n","for i in range(len(tokens)):\n","    if len(tokens[i]) < min_len:\n","        min_len = len(tokens[i])\n","        \n","print(\"Max length: \", max_len)\n","print(\"Min length: \", min_len)\n","\n","# number of sentences with length > 100\n","count = 0\n","for i in range(len(tokens)):\n","    if len(tokens[i]) > 250:\n","        count += 1\n","        \n","print(\"Number of sentences with length > 250: \", count)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:30:40.043150Z","iopub.status.busy":"2023-10-31T21:30:40.042757Z","iopub.status.idle":"2023-10-31T21:30:40.542779Z","shell.execute_reply":"2023-10-31T21:30:40.541730Z","shell.execute_reply.started":"2023-10-31T21:30:40.043118Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["565093\n","565093\n","43463\n","43463\n"]}],"source":["# remove sentences with length > 100 along with their labels\n","new_tokens = []\n","new_labels = []\n","for i in range(len(tokens)):\n","    if len(tokens[i]) <= 250:\n","        new_tokens.append(tokens[i])\n","        new_labels.append(train_labels[i])\n","        \n","# remove so in test also\n","new_tokens_test = []\n","new_labels_test = []\n","for i in range(len(tokens_test)):\n","    if len(tokens_test[i]) <= 250:\n","        new_tokens_test.append(tokens_test[i])\n","        new_labels_test.append(test_labels[i])\n","        \n","print(len(new_tokens))\n","print(len(new_labels))\n","print(len(new_tokens_test))\n","print(len(new_labels_test))"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:31:17.518746Z","iopub.status.busy":"2023-10-31T21:31:17.518371Z","iopub.status.idle":"2023-10-31T21:31:17.563390Z","shell.execute_reply":"2023-10-31T21:31:17.562475Z","shell.execute_reply.started":"2023-10-31T21:31:17.518716Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Max length:  1024\n","Min length:  1\n"]}],"source":["# for tetst data\n","# find length of longest sentence\n","max_len_test = 0\n","for i in range(len(tokens_test)):\n","    if len(tokens_test[i]) > max_len_test:\n","        max_len_test = len(tokens_test[i])\n","        \n","# find length of shortest sentence\n","min_len_test = 1000000\n","for i in range(len(tokens_test)):\n","    if len(tokens_test[i]) < min_len_test:\n","        min_len_test = len(tokens_test[i])\n","        \n","print(\"Max length: \", max_len_test)\n","print(\"Min length: \", min_len_test)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:31:21.056703Z","iopub.status.busy":"2023-10-31T21:31:21.056350Z","iopub.status.idle":"2023-10-31T21:31:21.062304Z","shell.execute_reply":"2023-10-31T21:31:21.061409Z","shell.execute_reply.started":"2023-10-31T21:31:21.056678Z"},"trusted":true},"outputs":[],"source":["# add padding to all sentences and S and EOS tokens\n","def padding(tokens_list, max_len):\n","    for i in range(len(tokens_list)):\n","        tokens_list[i] = ['S'] + tokens_list[i] + ['EOS']\n","        while len(tokens_list[i]) < max_len:\n","            tokens_list[i].append('PAD')\n","    return tokens_list"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:31:26.284038Z","iopub.status.busy":"2023-10-31T21:31:26.283654Z","iopub.status.idle":"2023-10-31T21:32:04.532136Z","shell.execute_reply":"2023-10-31T21:32:04.531244Z","shell.execute_reply.started":"2023-10-31T21:31:26.284008Z"},"trusted":true},"outputs":[],"source":["max_len = 252\n","tokens = padding(new_tokens, max_len)\n","tokens_test = padding(new_tokens_test, max_len)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["565093\n","43463\n"]}],"source":["print(len(tokens))\n","print(len(tokens_test))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# split into train and validation using sklearn\n","from sklearn.model_selection import train_test_split\n","tokens, val_tokens, new_labels, val_labels = train_test_split(tokens, new_labels, test_size=0.1, random_state=42)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:32:04.534169Z","iopub.status.busy":"2023-10-31T21:32:04.533860Z","iopub.status.idle":"2023-10-31T21:32:09.140085Z","shell.execute_reply":"2023-10-31T21:32:09.138943Z","shell.execute_reply.started":"2023-10-31T21:32:04.534142Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fasching\n","69527\n","41061\n","20566\n","28756\n"]}],"source":["# Create a vocabulary by collecting unique words from the training data\n","vocab = set()\n","for token in tokens:\n","    vocab.update(token)\n","\n","# Create a dictionary to map words to indices in the vocabulary\n","word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n","idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n","\n","print(idx_to_word[0])\n","print(word_to_idx['UNK'])\n","print(word_to_idx['PAD'])\n","print(word_to_idx['S'])\n","print(word_to_idx['EOS'])\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:32:09.142197Z","iopub.status.busy":"2023-10-31T21:32:09.141537Z","iopub.status.idle":"2023-10-31T21:32:09.147312Z","shell.execute_reply":"2023-10-31T21:32:09.146296Z","shell.execute_reply.started":"2023-10-31T21:32:09.142159Z"},"trusted":true},"outputs":[],"source":["batch_size = 256\n","num_classes = 5\n","vocab_size = len(vocab)\n","num_epochs = 3\n","learning_rate = 0.001\n","embedding_size = 300\n","hidden_size = 128"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:44:44.935114Z","iopub.status.busy":"2023-10-31T21:44:44.934702Z","iopub.status.idle":"2023-10-31T21:45:52.868178Z","shell.execute_reply":"2023-10-31T21:45:52.867078Z","shell.execute_reply.started":"2023-10-31T21:44:44.935082Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTMCell, RNN, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","\n","# Convert tokens and labels to Keras format\n","# Note: Ensure tokens and new_labels are numpy arrays\n","X_train = [[word_to_idx.get(token, word_to_idx['UNK']) for token in sentence] for sentence in tokens]\n","X_val = [[word_to_idx.get(token, word_to_idx['UNK']) for token in sentence] for sentence in val_tokens]\n","X_test = [[word_to_idx.get(token, word_to_idx['UNK']) for token in sentence] for sentence in tokens_test]\n","X_train = np.array(X_train)\n","X_val = np.array(X_val)\n","X_test = np.array(X_test)\n","\n","# Convert labels to one-hot format\n","y_train = to_categorical(new_labels, num_classes=num_classes)\n","y_val = to_categorical(val_labels, num_classes=num_classes)\n","y_test = to_categorical(new_labels_test, num_classes=num_classes)\n","\n","# GPU Configuration\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if len(physical_devices) > 0:\n","    tf.config.experimental.set_memory_growth(physical_devices[0], True)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:46:28.723960Z","iopub.status.busy":"2023-10-31T21:46:28.722982Z","iopub.status.idle":"2023-10-31T21:46:28.865105Z","shell.execute_reply":"2023-10-31T21:46:28.863973Z","shell.execute_reply.started":"2023-10-31T21:46:28.723922Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"]}],"source":["# Model\n","model = Sequential()\n","model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, mask_zero=True))\n","model.add(RNN(LSTMCell(hidden_size)))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(optimizer=Adam(learning_rate=learning_rate),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-10-31T21:46:30.841406Z","iopub.status.busy":"2023-10-31T21:46:30.841016Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  98/1987 [>.............................] - ETA: 25:07 - loss: 1.6101 - accuracy: 0.2051"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m y_test_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_test, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m      7\u001b[0m     \n\u001b[1;32m      8\u001b[0m     \u001b[39m# history = model.fit(X_train, y_train, epochs=1, batch_size=256, shuffle=True, validation_data=(X_test, y_test))\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val))\n\u001b[1;32m     11\u001b[0m     \u001b[39m# Get the predictions\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Convert y_test from one-hot encoding to integer labels\n","y_test_labels = np.argmax(y_test, axis=1)\n","\n","for _ in range(num_epochs):\n","    \n","    # history = model.fit(X_train, y_train, epochs=1, batch_size=256, shuffle=True, validation_data=(X_test, y_test))\n","    history = model.fit(X_train, y_train, epochs=1, batch_size=256, shuffle=True, validation_data=(X_val, y_val))\n","    \n","    # Get the predictions\n","    y_pred = model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","    # Default accuracy\n","    print('Default Test Accuracy:', np.mean(y_pred_classes == y_test_labels) * 100)\n","\n","    # Custom accuracy calculation\n","    total = len(y_test)\n","    correct = 0\n","\n","    for i in range(total):\n","        diff = abs(y_pred_classes[i] - y_test_labels[i])\n","        if diff == 0:\n","            correct += 1\n","        elif diff == 1:\n","            correct += 0.75\n","        elif diff == 2:\n","            correct += 0.5\n","        elif diff == 3:\n","            correct += 0.25\n","\n","    # Calculate and print custom accuracy\n","    accuracy_ordinal = 100 * correct / total\n","    print(f'Ordinal Accuracy of the network on the {total} test inputs: {accuracy_ordinal} %')\n","\n","    # Classification report and confusion matrix\n","    print(classification_report(y_test_labels, y_pred_classes))\n","    print(confusion_matrix(y_test_labels, y_pred_classes))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5 (main, Aug 24 2023, 15:09:45) [Clang 14.0.3 (clang-1403.0.22.14.1)]"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":4}
